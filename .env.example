# OpenAI API Configuration
OPENAI_API_KEY=your-api-key-here

# Model Selection
# Options: text-embedding-3-small (cheaper), text-embedding-3-large (better quality)
EMBEDDING_MODEL=text-embedding-3-large

# Options: gpt-4o (recommended), gpt-4-turbo-preview (more expensive)
CHAT_MODEL=gpt-4o

# Search and Context Settings
# Number of relevant posts to use for context (default: 15)
DEFAULT_CONTEXT_POSTS=15

# Chunking Configuration
# Tokens per chunk (default: 512)
CHUNK_SIZE=512
# Overlap between chunks in tokens (default: 50)
CHUNK_OVERLAP=50

# Compression Settings (EXPENSIVE - disabled by default)
# Enable context compression using GPT (can cost ~$0.20 per query if triggered)
ENABLE_COMPRESSION=false
# Threshold in tokens before compression kicks in (default: 100000 - effectively disabled)
COMPRESSION_THRESHOLD=100000

# Feature Flags
# Enable diversity re-ranking to avoid too many chunks from same post (default: true)
ENABLE_DIVERSITY=true
# Enable cost tracking and display (default: false)
ENABLE_COST_TRACKING=false

# Personality Configuration
# Path to Mr. Kaine's personality and knowledge base file (default: data/kaine_personality.md)
KAINE_PERSONALITY_FILE=data/kaine_personality.md
# Relevance score threshold below which the system enters speculation mode (default: 0.5)
# Lower values = more speculation; higher values = stricter factual responses
SPECULATION_THRESHOLD=0.5

# Configuration Notes:
# - Setting ENABLE_COMPRESSION=true can significantly increase costs
# - Lower COMPRESSION_THRESHOLD values trigger compression more often
# - ENABLE_COST_TRACKING=true will show cost estimates for each query
# - v1 uses separate embedding files (_v1_embeddings.pkl) to avoid conflicts

# ============================================================================
# Web Application Configuration (for web_app.py)
# ============================================================================

# Environment Mode
# Options: development, production
ENVIRONMENT=development

# Server Configuration
PORT=8000
WORKERS=4
LOG_LEVEL=INFO

# Redis Configuration (for persistent rate limiting)
# Format: redis://host:port/db or redis://user:pass@host:port/db
# Leave empty or comment out to use in-memory rate limiting
REDIS_URL=redis://redis:6379/0

# CORS Configuration
# Comma-separated list of allowed origins
# Use "*" for development, specific domains for production
# Example: ALLOWED_ORIGINS=https://yourdomain.com,https://www.yourdomain.com
ALLOWED_ORIGINS=*

# Rate Limiting
# Maximum number of requests per IP address
RATE_LIMIT_MAX_REQUESTS=10
# Time window in minutes
RATE_LIMIT_WINDOW_MINUTES=60

# Production Notes:
# 1. Set ENVIRONMENT=production in production deployments
# 2. Update ALLOWED_ORIGINS to your actual domain(s)
# 3. Ensure Redis is accessible if using REDIS_URL
# 4. Adjust WORKERS based on your server's CPU cores (typically 2-4x cores)
# 5. Set LOG_LEVEL=WARNING or ERROR in production to reduce log noise
