# OpenAI API Configuration
OPENAI_API_KEY=your-api-key-here

# Model Selection
# Options: text-embedding-3-small (cheaper), text-embedding-3-large (better quality)
EMBEDDING_MODEL=text-embedding-3-large

# Options: gpt-4o (recommended), gpt-4-turbo-preview (more expensive)
CHAT_MODEL=gpt-4o

# Search and Context Settings
# Number of relevant posts to use for context (default: 15)
DEFAULT_CONTEXT_POSTS=15

# Chunking Configuration
# Tokens per chunk (default: 512)
CHUNK_SIZE=512
# Overlap between chunks in tokens (default: 50)
CHUNK_OVERLAP=50

# Compression Settings (EXPENSIVE - disabled by default)
# Enable context compression using GPT (can cost ~$0.20 per query if triggered)
ENABLE_COMPRESSION=false
# Threshold in tokens before compression kicks in (default: 100000 - effectively disabled)
COMPRESSION_THRESHOLD=100000

# Feature Flags
# Enable diversity re-ranking to avoid too many chunks from same post (default: true)
ENABLE_DIVERSITY=true
# Enable cost tracking and display (default: false)
ENABLE_COST_TRACKING=false

# Configuration Notes:
# - Setting ENABLE_COMPRESSION=true can significantly increase costs
# - Lower COMPRESSION_THRESHOLD values trigger compression more often
# - ENABLE_COST_TRACKING=true will show cost estimates for each query
# - v1 uses separate embedding files (_v1_embeddings.pkl) to avoid conflicts
